{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Model Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This naive recommendation model leverages the **K-Nearest Neighbors** (**KNN**) algorithm to predict a user's ratings for anime they haven't rated yet. The fundamental idea is to find users who have rated the same anime in a way similar to the target user, and then use their ratings for other anime to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Identify Similar Users**\n",
    "    1. For a given user `U`, calculate the similarity between `U` and all other users based on their ratings for common anime.\n",
    "    2. Metric: We use **Cosine Similarity** to measure similarity. This metric considers the angle between rating vectors and is scale-invariant, making it suitable for sparse rating data.\n",
    "2. **Select Neighbors**\n",
    "    1. For each anime the target user hasn’t rated, identify other users who have rated that anime.\n",
    "    2. Among these users, select the top `K` most similar users (neighbors) based on the **Cosine Similarity** score.\n",
    "3. **Predict Ratings**\n",
    "    1. For each anime the target user hasn’t rated, predict its rating by calculating a weighted average of the ratings given by the `K` neighbors.\n",
    "    2. The weight for each neighbor’s rating is determined by their similarity score with the target user.\n",
    "    3. Rating for Anime `A` is predicted by formula:\n",
    "    $$ \n",
    "    A = \\frac{\\sum{i = 1}^K (Similarity(U, N_i) \\cdot Raiting(N_i, A))}{\\sum{i = 1}^K (Similarity(U, N_i))}\n",
    "    $$\n",
    "    , where $N_i$ is i-th neighbor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Cosine Similarity**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Definition**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine Similarity is a metric used to measure the similarity between two non-zero vectors in a multi-dimensional space. It calculates the cosine of the angle between the vectors, where the result ranges from -1 (completely opposite) to 1 (completely identical)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Mathematical Formula**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cosine similarity between two vectors $A$ and $B$ is defined as:\n",
    "\n",
    "$$\n",
    "\\text{Cosine Similarity}(A, B) = \\frac{\\sum_{i=1}^n A_i \\cdot B_i}{\\sqrt{\\sum_{i=1}^n A_i^2} \\cdot \\sqrt{\\sum_{i=1}^n B_i^2}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $A_i$ and $B_i$ represent the components of vectors $A$ and $B$.\n",
    "- The numerator is the dot product of the two vectors.\n",
    "- The denominator is the product of the magnitudes of the vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Properties**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Range:**  \n",
    "  $-1 \\leq \\text{Cosine Similarity}(A, B) \\leq 1$  \n",
    "  - **1:** The vectors are identical (point in the same direction).  \n",
    "  - **0:** The vectors are orthogonal (no similarity).  \n",
    "  - **-1:** The vectors are completely opposite.\n",
    "\n",
    "- **Normalization:**  \n",
    "  The metric normalizes the vectors, so it is scale-invariant. This means differences in magnitude (e.g., $A = [1, 2]$ vs $A = [10, 20]$) do not affect the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing requiered libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import some libraries requiered for this overview. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below comes from `data_helper.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to get data from provided databases and format it so we can easly find neighbours later. Getting rid of watched but not rated entires in the ratings table (there is no point in keeping unrated data we will just find next neighbour), as well as rows with missing data from the anime table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# get data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m anime \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(file_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/anime.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m ratings \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/rating.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# drop rows with missing values in 'genre' or 'rating' and missing IDs\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "file_path = \"../data\"\n",
    "anime = pd.read_csv(file_path + \"/anime.csv\")\n",
    "ratings = pd.read_csv(file_path + \"/rating.csv\")\n",
    "\n",
    "# drop rows with missing values in 'genre' or 'rating' and missing IDs\n",
    "anime = anime.dropna(subset=[\"genre\", \"rating\"])\n",
    "ratings = ratings.dropna(subset=[\"anime_id\", \"user_id\"])\n",
    "anime = anime.dropna(subset=[\"anime_id\"])\n",
    "\n",
    "# drop watched anime without rating\n",
    "ratings = ratings[ratings[\"rating\"] != -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create mappings between indexes and IDs. then makig sure there are no missing indexes by dropping it. There is so much data that deleting stuff makes little difference. We still end up with a big data set at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping of anime_id to index for matrix creation\n",
    "anime_id_to_index = {\n",
    "    anime_id: idx for idx, anime_id in enumerate(anime[\"anime_id\"].unique())\n",
    "}\n",
    "user_id_to_index = {\n",
    "    user_id: idx for idx, user_id in enumerate(ratings[\"user_id\"].unique())\n",
    "}\n",
    "\n",
    "# add index mappings to the ratings dataframe\n",
    "ratings[\"anime_idx\"] = ratings[\"anime_id\"].map(anime_id_to_index)\n",
    "ratings[\"user_idx\"] = ratings[\"user_id\"].map(user_id_to_index)\n",
    "\n",
    "# drop missing ids again\n",
    "ratings = ratings.dropna(subset=[\"anime_idx\", \"user_idx\"])\n",
    "\n",
    "# remove IDs\n",
    "ratings.drop([\"anime_id\", \"user_id\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of unique ratings: 19011438\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6337146 entries, 47 to 7813736\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   rating     int64  \n",
      " 1   anime_idx  float64\n",
      " 2   user_idx   int64  \n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 193.4 MB\n",
      "None \n",
      "\n",
      "\n",
      "     rating  anime_idx  user_idx\n",
      "47       10     1709.0         0\n",
      "81       10     1057.0         0\n",
      "83       10      804.0         0\n",
      "101      10      724.0         0\n",
      "153      10      122.0         1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Amount of unique ratings: {ratings.size}\\n\\n\")\n",
    "print(ratings.info(), \"\\n\\n\")\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below comes from `data_helper.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From individual ratings of users we want to create a matrix. This will be useful while looking for neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "ratings = ratings.groupby([\"user_idx\", \"anime_idx\"], as_index=False).mean()\n",
    "\n",
    "# create user-anime matrix\n",
    "user_anime_matrix = ratings.pivot(\n",
    "    index=\"user_idx\", columns=\"anime_idx\", values=\"rating\"\n",
    ").fillna(0)\n",
    "\n",
    "# convert matrix to numpy array for faster computations\n",
    "user_anime_array = user_anime_matrix.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anime_idx  0.0      1.0      2.0      3.0      4.0      5.0      6.0      \\\n",
      "user_idx                                                                   \n",
      "0              0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "1              0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "2              0.0     10.0      0.0      0.0      0.0      0.0      0.0   \n",
      "3              0.0      0.0      0.0      9.0      9.0      0.0      0.0   \n",
      "4              0.0      0.0      0.0      0.0      0.0      0.0      9.0   \n",
      "...            ...      ...      ...      ...      ...      ...      ...   \n",
      "69595          0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "69596          0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "69597          0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "69598          0.0     10.0      0.0      9.0      0.0      0.0      0.0   \n",
      "69599          0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "\n",
      "anime_idx  7.0      8.0      9.0      ...  12000.0  12004.0  12005.0  12009.0  \\\n",
      "user_idx                              ...                                       \n",
      "0              0.0      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
      "1              0.0      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
      "2              0.0      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
      "3              0.0     10.0      8.0  ...      0.0      0.0      0.0      0.0   \n",
      "4              0.0      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
      "...            ...      ...      ...  ...      ...      ...      ...      ...   \n",
      "69595          0.0      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
      "69596          0.0      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
      "69597          0.0      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
      "69598          0.0      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
      "69599          0.0      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
      "\n",
      "anime_idx  12010.0  12011.0  12012.0  12013.0  12014.0  12015.0  \n",
      "user_idx                                                         \n",
      "0              0.0      0.0      0.0      0.0      0.0      0.0  \n",
      "1              0.0      0.0      0.0      0.0      0.0      0.0  \n",
      "2              0.0      0.0      0.0      0.0      0.0      0.0  \n",
      "3              0.0      0.0      0.0      0.0      0.0      0.0  \n",
      "4              0.0      0.0      0.0      0.0      0.0      0.0  \n",
      "...            ...      ...      ...      ...      ...      ...  \n",
      "69595          0.0      0.0      0.0      0.0      0.0      0.0  \n",
      "69596          0.0      0.0      0.0      0.0      0.0      0.0  \n",
      "69597          0.0      0.0      0.0      0.0      0.0      0.0  \n",
      "69598          0.0      0.0      0.0      0.0      0.0      0.0  \n",
      "69599          0.0      0.0      0.0      0.0      0.0      0.0  \n",
      "\n",
      "[69600 rows x 9892 columns]\n"
     ]
    }
   ],
   "source": [
    "print(user_anime_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see the model itself. It may not be intuitive what is to `fit` and what to `predict`. In presented model we `fit` all the data and predict for the subset of the `data` given in list of users we want to make predictions for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are forced to a use custom **cosine similarity**. We want to skip empty cells in our computations. The reason for that skipping is simple we don't want our solution to identify lack of record as 0 -  we don't want to consider 1 and 10 to be more similar than 0 and 10. From the other hand we want 9 and 10 to be closer than 0 and 10. To achive something like that we will add penalty for lacking predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNRecommender:\n",
    "\n",
    "    def __init__(self, k=5, weight_factor=1.0, penalty_factor=0.1):\n",
    "        \"\"\"\n",
    "        Initialize the KNN Recommender model.\n",
    "\n",
    "        Parameters:\n",
    "        - k: Number of neighbors to consider (default is 5).\n",
    "        - weight_factor: Adjusts the influence of weights in the weighted average.\n",
    "                         A value of 1.0 uses the weights directly.\n",
    "                         A value > 1.0 increases the impact of highly similar neighbors.\n",
    "                         A value < 1.0 reduces the influence of weights.\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.weight_factor = weight_factor\n",
    "        self.penalty_factor = penalty_factor\n",
    "        self.user_anime_similarity = None\n",
    "        self.train_matrix = None\n",
    "\n",
    "    def _cosine_similarity_filtered(self, mat, min_common_ratings=2):\n",
    "        \"\"\" \n",
    "        Custom cosine similarity calculation considering only non-zero values.\n",
    "        Adds a penalty for pairs with few common ratings.\n",
    "\n",
    "        Parameters:\n",
    "        - mat: 2D numpy array where rows represent users and columns represent anime ratings.\n",
    "        - min_common_ratings: Minimum number of common ratings for similarity to be considered.\n",
    "        - penalty_factor: Reduces the similarity for pairs with fewer common ratings.\n",
    "                        A higher value increases the penalty for low overlap.\n",
    "        \"\"\"\n",
    "        n_users = mat.shape[0]\n",
    "        similarity = np.zeros((n_users, n_users))\n",
    "\n",
    "        for i in range(n_users):\n",
    "            for j in range(i + 1, n_users):\n",
    "                # Find indices where both users have rated the same anime (non-zero values)\n",
    "                valid_indices = (mat[i, :] > 0) & (mat[j, :] > 0)\n",
    "                num_common = np.sum(valid_indices)  # Number of common ratings\n",
    "\n",
    "                if num_common >= min_common_ratings:\n",
    "                    # Compute cosine similarity on these indices\n",
    "                    user_i_ratings = mat[i, valid_indices]\n",
    "                    user_j_ratings = mat[j, valid_indices]\n",
    "                    numerator = np.dot(user_i_ratings, user_j_ratings)\n",
    "                    denominator = np.sqrt(np.sum(user_i_ratings**2)) * np.sqrt(\n",
    "                        np.sum(user_j_ratings**2)\n",
    "                    )\n",
    "                    if denominator > 0:\n",
    "                        raw_similarity = numerator / denominator\n",
    "                        # Apply penalty for low overlap\n",
    "                        similarity[i, j] = similarity[j, i] = raw_similarity * (\n",
    "                            1 - self.penalty_factor / (num_common + 1e-9)\n",
    "                        )\n",
    "        return similarity + 1\n",
    "\n",
    "    def fit(self, train_matrix):\n",
    "        \"\"\"\n",
    "        Fit the model using the training user-anime rating matrix.\n",
    "\n",
    "        Parameters:\n",
    "        - train_matrix: A matrix where rows represent users, columns represent anime,\n",
    "                        and values are ratings. Missing ratings should be filled with 0.\n",
    "        \"\"\"\n",
    "        self.train_matrix = np.array(train_matrix)\n",
    "        self.user_anime_similarity = self._cosine_similarity_filtered(self.train_matrix)\n",
    "\n",
    "    def predict(self, user_indices):\n",
    "        \"\"\"\n",
    "        Predict ratings for specific users.\n",
    "\n",
    "        Args:\n",
    "            user_indices (list): List of user indices for whom to predict ratings.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: A matrix with predicted ratings for the given users (dtype=float64).\n",
    "        \"\"\"\n",
    "        if self.train_matrix is None or self.user_anime_similarity is None:\n",
    "            raise ValueError(\"The model must be fit before calling predict.\")\n",
    "\n",
    "        # Initialize an empty predictions matrix for the specified users\n",
    "        predictions = np.zeros((len(user_indices), self.train_matrix.shape[1]), dtype=np.float64)\n",
    "\n",
    "        # Iterate over the specified user indices\n",
    "        for idx, user in enumerate(user_indices):\n",
    "            # Get the indices of the user's unrated anime (0 in the training matrix)\n",
    "            unrated_anime_indices = np.where(self.train_matrix[user] == 0)[0]\n",
    "\n",
    "            for anime in range(len(self.train_matrix[user])):\n",
    "                if anime in unrated_anime_indices:\n",
    "                    # Find K most similar users who have rated this anime\n",
    "                    anime_ratings = self.train_matrix[:, anime]\n",
    "                    similar_users = [\n",
    "                        (other_user, self.user_anime_similarity[user, other_user])\n",
    "                        for other_user in range(self.train_matrix.shape[0])\n",
    "                        if anime_ratings[other_user] > 0 and other_user != user\n",
    "                    ]\n",
    "                    # Sort by similarity and take top K\n",
    "                    top_k_users = sorted(similar_users, key=lambda x: x[1], reverse=True)[: self.k]\n",
    "\n",
    "                    # Compute weighted average of ratings for the anime\n",
    "                    if top_k_users:\n",
    "                        numer = sum(\n",
    "                            (sim**self.weight_factor) * self.train_matrix[other_user, anime]\n",
    "                            for other_user, sim in top_k_users\n",
    "                        )\n",
    "                        denom = sum(sim**self.weight_factor for _, sim in top_k_users)\n",
    "                        predictions[idx, anime] = numer / (denom + 1e-9)\n",
    "                else:\n",
    "                    predictions[idx, anime] = self.train_matrix[user][anime]\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Ratings:\n",
      " [[10.          9.          5.          6.49900487  6.09091476]\n",
      " [ 9.36365619  8.          7.         10.          8.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Example dataset (rows = users, columns = anime, 0 = missing ratings)\n",
    "train_matrix = np.array(\n",
    "    [\n",
    "        [10, 9, 5, 0, 0],   # User 0\n",
    "        [0, 8, 6, 7, 0],    # User 1\n",
    "        [9, 8, 0, 6, 5],    # User 2\n",
    "        [0, 0, 7, 10, 8],   # User 3\n",
    "        [8, 9, 6, 0, 0],    # User 4\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initialize and train the model\n",
    "model = KNNRecommender(k=2, weight_factor=1.0, penalty_factor=0.5)\n",
    "model.fit(train_matrix)\n",
    "\n",
    "# Predict for users 0 and 3\n",
    "user_indices_to_predict = [0, 3]\n",
    "predicted_ratings = model.predict(user_indices_to_predict)\n",
    "\n",
    "# Display results\n",
    "print(\"Predicted Ratings:\\n\", predicted_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why it doesn't work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solution is very straightforward and may seem correct. However, a hidden problem becomes visible when we try to use it on a larger set of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](images/funny_screen.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all the users results in the creation of an overwhelming similarity matrix. Not only that but even if our program magically worked, it would be embarrassingly slow. Using all those users for comparisons is unpractical idea when we want to work with bigger set of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we make this model work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code beow comes from `naive_model.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make similarity matrix smaller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having our similarity matrix calculated once is really tempting. However, as we saw, it is too big to be stored. Moreover, every prediction would need a lot of time to sort out those similarities. Solution to this issue is to choose in out fit function only a part of users that will be used for finding similarities: `users_base`. \n",
    "\n",
    "To do so we want to choose users with possibly many ratings, those are really useful cause keeping them can give us more data needed for our predictions. Working with the data I found out the problem that some anime are \"avoided\" by users with many ratings. So we can't simply add some number of top users or even add them till we get a couple of ratings for each anime. We unfortunately have to actively seek for missing anime ratings with preference for users with many ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Counter for each anime\n",
    "anime_ratings_count = np.zeros(len(train_matrix[0]))\n",
    "\n",
    "# Anime where counter is too low - propably every anime\n",
    "remaining_anime = np.where(anime_ratings_count < min_ratings_per_anime)[0]\n",
    "\n",
    "users_base_set = set()\n",
    "\n",
    "anime_counters = {\n",
    "    anime: anime_ratings_count[anime]\n",
    "    for anime in range(self.train_matrix.shape[1])\n",
    "}\n",
    "\n",
    "while len(remaining_anime) > 0:\n",
    "    # Smallest number of raitings\n",
    "    target_anime = remaining_anime[\n",
    "        np.argmin([anime_counters[a] for a in remaining_anime])\n",
    "    ]\n",
    "\n",
    "    # Users who rated\n",
    "        users_who_rated = np.where(self.train_matrix[:, target_anime] > 0)[0]\n",
    "\n",
    "    if len(users_who_rated) > 0:\n",
    "        # Most useful user (has many raitings)\n",
    "        best_user = max(\n",
    "            users_who_rated, key=lambda u: np.sum(self.train_matrix[u] > 0)\n",
    "        )\n",
    "\n",
    "        users_base_set.add(best_user)\n",
    "        user_anime_indices = np.where(self.train_matrix[best_user] > 0)[0]\n",
    "        anime_counters[target_anime] -= 1\n",
    "        for anime in user_anime_indices:\n",
    "           anime_counters[anime] += 1\n",
    "\n",
    "    anime_counters[target_anime] += 1\n",
    "    remaining_anime = np.array(\n",
    "        [\n",
    "            anime\n",
    "            for anime in remaining_anime\n",
    "            if anime_counters[anime] < min_ratings_per_anime\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    self.users_base = list(users_base_set)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate similarity for each `predict()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to face the sad consequence of our decision. If we want to keep our similarity matrix smaller than for each `predict()` we have to calculate the similarity matrix for requested users with the use of users we have chosen as useful.\n",
    "`fit()` is expensive now. To avoid many fits we can move `k`, `weight_factor`, and `penalty_factor` to the `predict()` function. None of those is needed in our `fit()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def predict(self, user_indices, k=5, weight_factor=1.0, penalty_factor=0.1):\n",
    "\n",
    "        similarity = self._cosine_similarity_filtered(\n",
    "            self.train_matrix, user_indices, penalty_factor\n",
    "        )\n",
    "\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model becomes less accurate as it limits the used data. However, it works in reasonable time and space."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
